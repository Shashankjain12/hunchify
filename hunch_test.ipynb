{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "516f2ac9-5038-4901-b760-a1c9dd80d994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas\n",
    "# !pip install skimpy\n",
    "# !pip install matplotlib\n",
    "# !pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd0b69ca-fbc0-4486-b343-7c4c0c7f8150",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4db6309b-deeb-48de-9a52-ab65adc90ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"./data/raw/events.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd3e6c43-7e49-4f46-923d-7e3c5aa2944a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>createdAt</th>\n",
       "      <th>user_code</th>\n",
       "      <th>poll_code</th>\n",
       "      <th>event</th>\n",
       "      <th>country</th>\n",
       "      <th>city_code</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>college_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-12-29 18:30:10</td>\n",
       "      <td>user_2847</td>\n",
       "      <td>poll_27</td>\n",
       "      <td>Impression</td>\n",
       "      <td>country_1</td>\n",
       "      <td>city_1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-12-29 18:30:28</td>\n",
       "      <td>user_2847</td>\n",
       "      <td>poll_220</td>\n",
       "      <td>Impression</td>\n",
       "      <td>country_1</td>\n",
       "      <td>city_1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-12-29 18:30:38</td>\n",
       "      <td>user_2847</td>\n",
       "      <td>poll_190</td>\n",
       "      <td>Impression</td>\n",
       "      <td>country_1</td>\n",
       "      <td>city_1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-12-29 18:30:50</td>\n",
       "      <td>user_2847</td>\n",
       "      <td>poll_153</td>\n",
       "      <td>Impression</td>\n",
       "      <td>country_1</td>\n",
       "      <td>city_1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-12-29 18:31:34</td>\n",
       "      <td>user_2847</td>\n",
       "      <td>poll_42</td>\n",
       "      <td>Impression</td>\n",
       "      <td>country_1</td>\n",
       "      <td>city_1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232724</th>\n",
       "      <td>2023-01-17 14:18:13</td>\n",
       "      <td>user_131</td>\n",
       "      <td>poll_706</td>\n",
       "      <td>Polls Answered</td>\n",
       "      <td>country_1</td>\n",
       "      <td>city_11</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232725</th>\n",
       "      <td>2022-12-31 22:14:53</td>\n",
       "      <td>user_55</td>\n",
       "      <td>poll_707</td>\n",
       "      <td>Polls Answered</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232726</th>\n",
       "      <td>2022-12-31 21:49:54</td>\n",
       "      <td>user_57</td>\n",
       "      <td>poll_707</td>\n",
       "      <td>Polls Answered</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232727</th>\n",
       "      <td>2022-12-31 21:39:52</td>\n",
       "      <td>user_71</td>\n",
       "      <td>poll_707</td>\n",
       "      <td>Polls Answered</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232728</th>\n",
       "      <td>2022-12-31 20:12:15</td>\n",
       "      <td>user_415</td>\n",
       "      <td>poll_707</td>\n",
       "      <td>Polls Answered</td>\n",
       "      <td>country_1</td>\n",
       "      <td>city_1</td>\n",
       "      <td>male</td>\n",
       "      <td>19.0</td>\n",
       "      <td>Sri Guru Tegh Bahadur Khalsa College</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>231649 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 createdAt  user_code poll_code           event    country  \\\n",
       "0      2022-12-29 18:30:10  user_2847   poll_27      Impression  country_1   \n",
       "1      2022-12-29 18:30:28  user_2847  poll_220      Impression  country_1   \n",
       "2      2022-12-29 18:30:38  user_2847  poll_190      Impression  country_1   \n",
       "3      2022-12-29 18:30:50  user_2847  poll_153      Impression  country_1   \n",
       "4      2022-12-29 18:31:34  user_2847   poll_42      Impression  country_1   \n",
       "...                    ...        ...       ...             ...        ...   \n",
       "232724 2023-01-17 14:18:13   user_131  poll_706  Polls Answered  country_1   \n",
       "232725 2022-12-31 22:14:53    user_55  poll_707  Polls Answered        NaN   \n",
       "232726 2022-12-31 21:49:54    user_57  poll_707  Polls Answered        NaN   \n",
       "232727 2022-12-31 21:39:52    user_71  poll_707  Polls Answered        NaN   \n",
       "232728 2022-12-31 20:12:15   user_415  poll_707  Polls Answered  country_1   \n",
       "\n",
       "       city_code gender   age                          college_code  \n",
       "0         city_1    NaN   NaN                                   NaN  \n",
       "1         city_1    NaN   NaN                                   NaN  \n",
       "2         city_1    NaN   NaN                                   NaN  \n",
       "3         city_1    NaN   NaN                                   NaN  \n",
       "4         city_1    NaN   NaN                                   NaN  \n",
       "...          ...    ...   ...                                   ...  \n",
       "232724   city_11   male  26.0                                 Other  \n",
       "232725       NaN    NaN   NaN                                   NaN  \n",
       "232726       NaN    NaN   NaN                                   NaN  \n",
       "232727       NaN    NaN   NaN                                   NaN  \n",
       "232728    city_1   male  19.0  Sri Guru Tegh Bahadur Khalsa College  \n",
       "\n",
       "[231649 rows x 9 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa617cc-ba33-453a-ae65-9259b2f22fb2",
   "metadata": {},
   "source": [
    "## Events clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa965e21-7ee2-47ba-ab25-0fbb4ccadfb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>createdAt</th>\n",
       "      <th>user_code</th>\n",
       "      <th>poll_code</th>\n",
       "      <th>event</th>\n",
       "      <th>country</th>\n",
       "      <th>city_code</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>college_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-12-29 18:30:10</td>\n",
       "      <td>user_2847</td>\n",
       "      <td>poll_27</td>\n",
       "      <td>Impression</td>\n",
       "      <td>country_1</td>\n",
       "      <td>city_1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-12-29 18:30:28</td>\n",
       "      <td>user_2847</td>\n",
       "      <td>poll_220</td>\n",
       "      <td>Impression</td>\n",
       "      <td>country_1</td>\n",
       "      <td>city_1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-12-29 18:30:38</td>\n",
       "      <td>user_2847</td>\n",
       "      <td>poll_190</td>\n",
       "      <td>Impression</td>\n",
       "      <td>country_1</td>\n",
       "      <td>city_1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-12-29 18:30:50</td>\n",
       "      <td>user_2847</td>\n",
       "      <td>poll_153</td>\n",
       "      <td>Impression</td>\n",
       "      <td>country_1</td>\n",
       "      <td>city_1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-12-29 18:31:34</td>\n",
       "      <td>user_2847</td>\n",
       "      <td>poll_42</td>\n",
       "      <td>Impression</td>\n",
       "      <td>country_1</td>\n",
       "      <td>city_1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            createdAt  user_code poll_code       event    country city_code  \\\n",
       "0 2022-12-29 18:30:10  user_2847   poll_27  Impression  country_1    city_1   \n",
       "1 2022-12-29 18:30:28  user_2847  poll_220  Impression  country_1    city_1   \n",
       "2 2022-12-29 18:30:38  user_2847  poll_190  Impression  country_1    city_1   \n",
       "3 2022-12-29 18:30:50  user_2847  poll_153  Impression  country_1    city_1   \n",
       "4 2022-12-29 18:31:34  user_2847   poll_42  Impression  country_1    city_1   \n",
       "\n",
       "  gender  age college_code  \n",
       "0    NaN  NaN          NaN  \n",
       "1    NaN  NaN          NaN  \n",
       "2    NaN  NaN          NaN  \n",
       "3    NaN  NaN          NaN  \n",
       "4    NaN  NaN          NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 231649 entries, 0 to 232728\n",
      "Data columns (total 9 columns):\n",
      " #   Column        Non-Null Count   Dtype         \n",
      "---  ------        --------------   -----         \n",
      " 0   createdAt     231649 non-null  datetime64[ns]\n",
      " 1   user_code     231649 non-null  object        \n",
      " 2   poll_code     231649 non-null  object        \n",
      " 3   event         231649 non-null  object        \n",
      " 4   country       219812 non-null  object        \n",
      " 5   city_code     218467 non-null  object        \n",
      " 6   gender        168868 non-null  object        \n",
      " 7   age           162288 non-null  float64       \n",
      " 8   college_code  101878 non-null  object        \n",
      "dtypes: datetime64[ns](1), float64(1), object(7)\n",
      "memory usage: 17.7+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭──────────────────────────────────────────────── skimpy summary ─────────────────────────────────────────────────╮\n",
       "│ <span style=\"font-style: italic\">         Data Summary         </span> <span style=\"font-style: italic\">      Data Types       </span> <span style=\"font-style: italic\">       Categories        </span>                                │\n",
       "│ ┏━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓ ┏━━━━━━━━━━━━━┳━━━━━━━┓ ┏━━━━━━━━━━━━━━━━━━━━━━━┓                                │\n",
       "│ ┃<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> dataframe         </span>┃<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> Values </span>┃ ┃<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> Column Type </span>┃<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> Count </span>┃ ┃<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> Categorical Variables </span>┃                                │\n",
       "│ ┡━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩ ┡━━━━━━━━━━━━━╇━━━━━━━┩ ┡━━━━━━━━━━━━━━━━━━━━━━━┩                                │\n",
       "│ │ Number of rows    │ 231649 │ │ category    │ 7     │ │ user_code             │                                │\n",
       "│ │ Number of columns │ 9      │ │ datetime64  │ 1     │ │ poll_code             │                                │\n",
       "│ └───────────────────┴────────┘ │ float64     │ 1     │ │ event                 │                                │\n",
       "│                                └─────────────┴───────┘ │ country               │                                │\n",
       "│                                                        │ city_code             │                                │\n",
       "│                                                        │ gender                │                                │\n",
       "│                                                        │ college_code          │                                │\n",
       "│                                                        └───────────────────────┘                                │\n",
       "│ <span style=\"font-style: italic\">                                                    number                                                    </span>  │\n",
       "│ ┏━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━┳━━━━━━━┳━━━━━━┳━━━━━━━┳━━━━━━━┳━━━━━━━┳━━━━━━━━┳━━━━━━━━━┓  │\n",
       "│ ┃<span style=\"font-weight: bold\"> column_name      </span>┃<span style=\"font-weight: bold\"> NA       </span>┃<span style=\"font-weight: bold\"> NA %     </span>┃<span style=\"font-weight: bold\"> mean    </span>┃<span style=\"font-weight: bold\"> sd    </span>┃<span style=\"font-weight: bold\"> p0   </span>┃<span style=\"font-weight: bold\"> p25   </span>┃<span style=\"font-weight: bold\"> p50   </span>┃<span style=\"font-weight: bold\"> p75   </span>┃<span style=\"font-weight: bold\"> p100   </span>┃<span style=\"font-weight: bold\"> hist    </span>┃  │\n",
       "│ ┡━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━━╇━━━━━━━╇━━━━━━╇━━━━━━━╇━━━━━━━╇━━━━━━━╇━━━━━━━━╇━━━━━━━━━┩  │\n",
       "│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">age             </span> │ <span style=\"color: #008080; text-decoration-color: #008080\">   69361</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">   29.94</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">     21</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">  4.8</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">   1</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">   19</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">   20</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">   22</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">    61</span> │ <span style=\"color: #008000; text-decoration-color: #008000\">  ▇▆▁  </span> │  │\n",
       "│ └──────────────────┴──────────┴──────────┴─────────┴───────┴──────┴───────┴───────┴───────┴────────┴─────────┘  │\n",
       "│ <span style=\"font-style: italic\">                                                   category                                                   </span>  │\n",
       "│ ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓  │\n",
       "│ ┃<span style=\"font-weight: bold\"> column_name                    </span>┃<span style=\"font-weight: bold\"> NA               </span>┃<span style=\"font-weight: bold\"> NA %           </span>┃<span style=\"font-weight: bold\"> ordered             </span>┃<span style=\"font-weight: bold\"> unique          </span>┃  │\n",
       "│ ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩  │\n",
       "│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">user_code                     </span> │ <span style=\"color: #008080; text-decoration-color: #008080\">               0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">             0</span> │ <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">False              </span> │ <span style=\"color: #008080; text-decoration-color: #008080\">           4200</span> │  │\n",
       "│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">poll_code                     </span> │ <span style=\"color: #008080; text-decoration-color: #008080\">               0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">             0</span> │ <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">False              </span> │ <span style=\"color: #008080; text-decoration-color: #008080\">            707</span> │  │\n",
       "│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">event                         </span> │ <span style=\"color: #008080; text-decoration-color: #008080\">               0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">             0</span> │ <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">False              </span> │ <span style=\"color: #008080; text-decoration-color: #008080\">              4</span> │  │\n",
       "│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">country                       </span> │ <span style=\"color: #008080; text-decoration-color: #008080\">           11837</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">          5.11</span> │ <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">False              </span> │ <span style=\"color: #008080; text-decoration-color: #008080\">             26</span> │  │\n",
       "│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">city_code                     </span> │ <span style=\"color: #008080; text-decoration-color: #008080\">           13182</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">          5.69</span> │ <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">False              </span> │ <span style=\"color: #008080; text-decoration-color: #008080\">            132</span> │  │\n",
       "│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">gender                        </span> │ <span style=\"color: #008080; text-decoration-color: #008080\">           62781</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">          27.1</span> │ <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">False              </span> │ <span style=\"color: #008080; text-decoration-color: #008080\">              4</span> │  │\n",
       "│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">college_code                  </span> │ <span style=\"color: #008080; text-decoration-color: #008080\">          129771</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">         56.02</span> │ <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">False              </span> │ <span style=\"color: #008080; text-decoration-color: #008080\">             93</span> │  │\n",
       "│ └────────────────────────────────┴──────────────────┴────────────────┴─────────────────────┴─────────────────┘  │\n",
       "│ <span style=\"font-style: italic\">                                                   datetime                                                   </span>  │\n",
       "│ ┏━━━━━━━━━━━━━━━━━━┳━━━━━━┳━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━┓  │\n",
       "│ ┃<span style=\"font-weight: bold\"> column_name      </span>┃<span style=\"font-weight: bold\"> NA   </span>┃<span style=\"font-weight: bold\"> NA %    </span>┃<span style=\"font-weight: bold\"> first                      </span>┃<span style=\"font-weight: bold\"> last                       </span>┃<span style=\"font-weight: bold\"> frequency    </span>┃  │\n",
       "│ ┡━━━━━━━━━━━━━━━━━━╇━━━━━━╇━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━┩  │\n",
       "│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">createdAt       </span> │ <span style=\"color: #008080; text-decoration-color: #008080\">   0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">      0</span> │ <span style=\"color: #800000; text-decoration-color: #800000\">   2022-12-19 16:30:24    </span> │ <span style=\"color: #800000; text-decoration-color: #800000\">   2023-01-30 08:38:30    </span> │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">None        </span> │  │\n",
       "│ └──────────────────┴──────┴─────────┴────────────────────────────┴────────────────────────────┴──────────────┘  │\n",
       "╰────────────────────────────────────────────────────── End ──────────────────────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭──────────────────────────────────────────────── skimpy summary ─────────────────────────────────────────────────╮\n",
       "│ \u001b[3m         Data Summary         \u001b[0m \u001b[3m      Data Types       \u001b[0m \u001b[3m       Categories        \u001b[0m                                │\n",
       "│ ┏━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓ ┏━━━━━━━━━━━━━┳━━━━━━━┓ ┏━━━━━━━━━━━━━━━━━━━━━━━┓                                │\n",
       "│ ┃\u001b[1;36m \u001b[0m\u001b[1;36mdataframe        \u001b[0m\u001b[1;36m \u001b[0m┃\u001b[1;36m \u001b[0m\u001b[1;36mValues\u001b[0m\u001b[1;36m \u001b[0m┃ ┃\u001b[1;36m \u001b[0m\u001b[1;36mColumn Type\u001b[0m\u001b[1;36m \u001b[0m┃\u001b[1;36m \u001b[0m\u001b[1;36mCount\u001b[0m\u001b[1;36m \u001b[0m┃ ┃\u001b[1;36m \u001b[0m\u001b[1;36mCategorical Variables\u001b[0m\u001b[1;36m \u001b[0m┃                                │\n",
       "│ ┡━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩ ┡━━━━━━━━━━━━━╇━━━━━━━┩ ┡━━━━━━━━━━━━━━━━━━━━━━━┩                                │\n",
       "│ │ Number of rows    │ 231649 │ │ category    │ 7     │ │ user_code             │                                │\n",
       "│ │ Number of columns │ 9      │ │ datetime64  │ 1     │ │ poll_code             │                                │\n",
       "│ └───────────────────┴────────┘ │ float64     │ 1     │ │ event                 │                                │\n",
       "│                                └─────────────┴───────┘ │ country               │                                │\n",
       "│                                                        │ city_code             │                                │\n",
       "│                                                        │ gender                │                                │\n",
       "│                                                        │ college_code          │                                │\n",
       "│                                                        └───────────────────────┘                                │\n",
       "│ \u001b[3m                                                    number                                                    \u001b[0m  │\n",
       "│ ┏━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━┳━━━━━━━┳━━━━━━┳━━━━━━━┳━━━━━━━┳━━━━━━━┳━━━━━━━━┳━━━━━━━━━┓  │\n",
       "│ ┃\u001b[1m \u001b[0m\u001b[1mcolumn_name     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mNA      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mNA %    \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mmean   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1msd   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mp0  \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mp25  \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mp50  \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mp75  \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mp100  \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mhist   \u001b[0m\u001b[1m \u001b[0m┃  │\n",
       "│ ┡━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━━╇━━━━━━━╇━━━━━━╇━━━━━━━╇━━━━━━━╇━━━━━━━╇━━━━━━━━╇━━━━━━━━━┩  │\n",
       "│ │ \u001b[38;5;141mage             \u001b[0m │ \u001b[36m   69361\u001b[0m │ \u001b[36m   29.94\u001b[0m │ \u001b[36m     21\u001b[0m │ \u001b[36m  4.8\u001b[0m │ \u001b[36m   1\u001b[0m │ \u001b[36m   19\u001b[0m │ \u001b[36m   20\u001b[0m │ \u001b[36m   22\u001b[0m │ \u001b[36m    61\u001b[0m │ \u001b[32m  ▇▆▁  \u001b[0m │  │\n",
       "│ └──────────────────┴──────────┴──────────┴─────────┴───────┴──────┴───────┴───────┴───────┴────────┴─────────┘  │\n",
       "│ \u001b[3m                                                   category                                                   \u001b[0m  │\n",
       "│ ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓  │\n",
       "│ ┃\u001b[1m \u001b[0m\u001b[1mcolumn_name                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mNA              \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mNA %          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mordered            \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1munique         \u001b[0m\u001b[1m \u001b[0m┃  │\n",
       "│ ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩  │\n",
       "│ │ \u001b[38;5;141muser_code                     \u001b[0m │ \u001b[36m               0\u001b[0m │ \u001b[36m             0\u001b[0m │ \u001b[38;5;45mFalse              \u001b[0m │ \u001b[36m           4200\u001b[0m │  │\n",
       "│ │ \u001b[38;5;141mpoll_code                     \u001b[0m │ \u001b[36m               0\u001b[0m │ \u001b[36m             0\u001b[0m │ \u001b[38;5;45mFalse              \u001b[0m │ \u001b[36m            707\u001b[0m │  │\n",
       "│ │ \u001b[38;5;141mevent                         \u001b[0m │ \u001b[36m               0\u001b[0m │ \u001b[36m             0\u001b[0m │ \u001b[38;5;45mFalse              \u001b[0m │ \u001b[36m              4\u001b[0m │  │\n",
       "│ │ \u001b[38;5;141mcountry                       \u001b[0m │ \u001b[36m           11837\u001b[0m │ \u001b[36m          5.11\u001b[0m │ \u001b[38;5;45mFalse              \u001b[0m │ \u001b[36m             26\u001b[0m │  │\n",
       "│ │ \u001b[38;5;141mcity_code                     \u001b[0m │ \u001b[36m           13182\u001b[0m │ \u001b[36m          5.69\u001b[0m │ \u001b[38;5;45mFalse              \u001b[0m │ \u001b[36m            132\u001b[0m │  │\n",
       "│ │ \u001b[38;5;141mgender                        \u001b[0m │ \u001b[36m           62781\u001b[0m │ \u001b[36m          27.1\u001b[0m │ \u001b[38;5;45mFalse              \u001b[0m │ \u001b[36m              4\u001b[0m │  │\n",
       "│ │ \u001b[38;5;141mcollege_code                  \u001b[0m │ \u001b[36m          129771\u001b[0m │ \u001b[36m         56.02\u001b[0m │ \u001b[38;5;45mFalse              \u001b[0m │ \u001b[36m             93\u001b[0m │  │\n",
       "│ └────────────────────────────────┴──────────────────┴────────────────┴─────────────────────┴─────────────────┘  │\n",
       "│ \u001b[3m                                                   datetime                                                   \u001b[0m  │\n",
       "│ ┏━━━━━━━━━━━━━━━━━━┳━━━━━━┳━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━┓  │\n",
       "│ ┃\u001b[1m \u001b[0m\u001b[1mcolumn_name     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mNA  \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mNA %   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mfirst                     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mlast                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mfrequency   \u001b[0m\u001b[1m \u001b[0m┃  │\n",
       "│ ┡━━━━━━━━━━━━━━━━━━╇━━━━━━╇━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━┩  │\n",
       "│ │ \u001b[38;5;141mcreatedAt       \u001b[0m │ \u001b[36m   0\u001b[0m │ \u001b[36m      0\u001b[0m │ \u001b[31m   2022-12-19 16:30:24    \u001b[0m │ \u001b[31m   2023-01-30 08:38:30    \u001b[0m │ \u001b[38;5;141mNone        \u001b[0m │  │\n",
       "│ └──────────────────┴──────┴─────────┴────────────────────────────┴────────────────────────────┴──────────────┘  │\n",
       "╰────────────────────────────────────────────────────── End ──────────────────────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of potential duplicates: 217\n",
      "\n",
      "user_code: user_code\n",
      "user_212     0.737327\n",
      "user_1797    0.013825\n",
      "user_136     0.009217\n",
      "user_3359    0.009217\n",
      "user_4067    0.009217\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "poll_code: poll_code\n",
      "poll_620    0.064516\n",
      "poll_549    0.036866\n",
      "poll_443    0.036866\n",
      "poll_96     0.027650\n",
      "poll_277    0.027650\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "event: event\n",
      "Impression        0.580645\n",
      "Polls Answered    0.313364\n",
      "Expand            0.055300\n",
      "Shares            0.050691\n",
      "Name: proportion, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>createdAt</th>\n",
       "      <th>user_code</th>\n",
       "      <th>poll_code</th>\n",
       "      <th>event</th>\n",
       "      <th>country</th>\n",
       "      <th>city_code</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>college_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>114877</th>\n",
       "      <td>2023-01-26 11:21:08</td>\n",
       "      <td>user_136</td>\n",
       "      <td>poll_620</td>\n",
       "      <td>Expand</td>\n",
       "      <td>country_1</td>\n",
       "      <td>city_1</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>Ramjas College</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114878</th>\n",
       "      <td>2023-01-26 11:21:08</td>\n",
       "      <td>user_136</td>\n",
       "      <td>poll_620</td>\n",
       "      <td>Expand</td>\n",
       "      <td>country_1</td>\n",
       "      <td>city_1</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>Ramjas College</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59793</th>\n",
       "      <td>2023-01-28 13:02:16</td>\n",
       "      <td>user_209</td>\n",
       "      <td>poll_449</td>\n",
       "      <td>Expand</td>\n",
       "      <td>country_1</td>\n",
       "      <td>city_1</td>\n",
       "      <td>male</td>\n",
       "      <td>23.0</td>\n",
       "      <td>St.Stephen's College</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59794</th>\n",
       "      <td>2023-01-28 13:02:16</td>\n",
       "      <td>user_209</td>\n",
       "      <td>poll_449</td>\n",
       "      <td>Expand</td>\n",
       "      <td>country_1</td>\n",
       "      <td>city_1</td>\n",
       "      <td>male</td>\n",
       "      <td>23.0</td>\n",
       "      <td>St.Stephen's College</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109321</th>\n",
       "      <td>2023-01-23 15:54:26</td>\n",
       "      <td>user_212</td>\n",
       "      <td>poll_549</td>\n",
       "      <td>Expand</td>\n",
       "      <td>country_1</td>\n",
       "      <td>city_1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105939</th>\n",
       "      <td>2022-12-30 15:33:22</td>\n",
       "      <td>user_1234</td>\n",
       "      <td>poll_76</td>\n",
       "      <td>Impression</td>\n",
       "      <td>country_1</td>\n",
       "      <td>city_1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105940</th>\n",
       "      <td>2022-12-30 15:33:22</td>\n",
       "      <td>user_1234</td>\n",
       "      <td>poll_76</td>\n",
       "      <td>Impression</td>\n",
       "      <td>country_1</td>\n",
       "      <td>city_1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115500</th>\n",
       "      <td>2023-01-13 15:13:07</td>\n",
       "      <td>user_127</td>\n",
       "      <td>poll_583</td>\n",
       "      <td>Impression</td>\n",
       "      <td>country_1</td>\n",
       "      <td>city_1</td>\n",
       "      <td>male</td>\n",
       "      <td>28.0</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115501</th>\n",
       "      <td>2023-01-13 15:13:07</td>\n",
       "      <td>user_127</td>\n",
       "      <td>poll_583</td>\n",
       "      <td>Impression</td>\n",
       "      <td>country_1</td>\n",
       "      <td>city_1</td>\n",
       "      <td>male</td>\n",
       "      <td>28.0</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100718</th>\n",
       "      <td>2023-01-28 12:13:23</td>\n",
       "      <td>user_159</td>\n",
       "      <td>poll_67</td>\n",
       "      <td>Impression</td>\n",
       "      <td>country_1</td>\n",
       "      <td>city_10</td>\n",
       "      <td>male</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154871</th>\n",
       "      <td>2023-01-23 15:51:53</td>\n",
       "      <td>user_212</td>\n",
       "      <td>poll_103</td>\n",
       "      <td>Polls Answered</td>\n",
       "      <td>country_1</td>\n",
       "      <td>city_1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154872</th>\n",
       "      <td>2023-01-23 15:51:53</td>\n",
       "      <td>user_212</td>\n",
       "      <td>poll_103</td>\n",
       "      <td>Polls Answered</td>\n",
       "      <td>country_1</td>\n",
       "      <td>city_1</td>\n",
       "      <td>male</td>\n",
       "      <td>19.0</td>\n",
       "      <td>Kirori Mal College</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210312</th>\n",
       "      <td>2023-01-23 15:51:26</td>\n",
       "      <td>user_212</td>\n",
       "      <td>poll_106</td>\n",
       "      <td>Polls Answered</td>\n",
       "      <td>country_1</td>\n",
       "      <td>city_1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210313</th>\n",
       "      <td>2023-01-23 15:51:26</td>\n",
       "      <td>user_212</td>\n",
       "      <td>poll_106</td>\n",
       "      <td>Polls Answered</td>\n",
       "      <td>country_1</td>\n",
       "      <td>city_1</td>\n",
       "      <td>male</td>\n",
       "      <td>19.0</td>\n",
       "      <td>Kirori Mal College</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139291</th>\n",
       "      <td>2023-01-23 15:52:13</td>\n",
       "      <td>user_212</td>\n",
       "      <td>poll_109</td>\n",
       "      <td>Polls Answered</td>\n",
       "      <td>country_1</td>\n",
       "      <td>city_1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108275</th>\n",
       "      <td>2023-01-23 04:33:08</td>\n",
       "      <td>user_165</td>\n",
       "      <td>poll_19</td>\n",
       "      <td>Shares</td>\n",
       "      <td>country_1</td>\n",
       "      <td>city_1</td>\n",
       "      <td>non_binary</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Delhi Technological University (DTU)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108276</th>\n",
       "      <td>2023-01-23 04:33:08</td>\n",
       "      <td>user_165</td>\n",
       "      <td>poll_19</td>\n",
       "      <td>Shares</td>\n",
       "      <td>country_1</td>\n",
       "      <td>city_1</td>\n",
       "      <td>non_binary</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Delhi Technological University (DTU)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108347</th>\n",
       "      <td>2023-01-13 12:08:55</td>\n",
       "      <td>user_1797</td>\n",
       "      <td>poll_139</td>\n",
       "      <td>Shares</td>\n",
       "      <td>country_1</td>\n",
       "      <td>city_1</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108348</th>\n",
       "      <td>2023-01-13 12:08:55</td>\n",
       "      <td>user_1797</td>\n",
       "      <td>poll_139</td>\n",
       "      <td>Shares</td>\n",
       "      <td>country_1</td>\n",
       "      <td>city_1</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108349</th>\n",
       "      <td>2023-01-13 12:08:55</td>\n",
       "      <td>user_1797</td>\n",
       "      <td>poll_139</td>\n",
       "      <td>Shares</td>\n",
       "      <td>country_1</td>\n",
       "      <td>city_1</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 createdAt  user_code poll_code           event    country  \\\n",
       "114877 2023-01-26 11:21:08   user_136  poll_620          Expand  country_1   \n",
       "114878 2023-01-26 11:21:08   user_136  poll_620          Expand  country_1   \n",
       "59793  2023-01-28 13:02:16   user_209  poll_449          Expand  country_1   \n",
       "59794  2023-01-28 13:02:16   user_209  poll_449          Expand  country_1   \n",
       "109321 2023-01-23 15:54:26   user_212  poll_549          Expand  country_1   \n",
       "105939 2022-12-30 15:33:22  user_1234   poll_76      Impression  country_1   \n",
       "105940 2022-12-30 15:33:22  user_1234   poll_76      Impression  country_1   \n",
       "115500 2023-01-13 15:13:07   user_127  poll_583      Impression  country_1   \n",
       "115501 2023-01-13 15:13:07   user_127  poll_583      Impression  country_1   \n",
       "100718 2023-01-28 12:13:23   user_159   poll_67      Impression  country_1   \n",
       "154871 2023-01-23 15:51:53   user_212  poll_103  Polls Answered  country_1   \n",
       "154872 2023-01-23 15:51:53   user_212  poll_103  Polls Answered  country_1   \n",
       "210312 2023-01-23 15:51:26   user_212  poll_106  Polls Answered  country_1   \n",
       "210313 2023-01-23 15:51:26   user_212  poll_106  Polls Answered  country_1   \n",
       "139291 2023-01-23 15:52:13   user_212  poll_109  Polls Answered  country_1   \n",
       "108275 2023-01-23 04:33:08   user_165   poll_19          Shares  country_1   \n",
       "108276 2023-01-23 04:33:08   user_165   poll_19          Shares  country_1   \n",
       "108347 2023-01-13 12:08:55  user_1797  poll_139          Shares  country_1   \n",
       "108348 2023-01-13 12:08:55  user_1797  poll_139          Shares  country_1   \n",
       "108349 2023-01-13 12:08:55  user_1797  poll_139          Shares  country_1   \n",
       "\n",
       "       city_code      gender   age                          college_code  \n",
       "114877    city_1        male  32.0                        Ramjas College  \n",
       "114878    city_1        male  32.0                        Ramjas College  \n",
       "59793     city_1        male  23.0                  St.Stephen's College  \n",
       "59794     city_1        male  23.0                  St.Stephen's College  \n",
       "109321    city_1         NaN   NaN                                   NaN  \n",
       "105939    city_1         NaN   NaN                                   NaN  \n",
       "105940    city_1         NaN   NaN                                   NaN  \n",
       "115500    city_1        male  28.0                                 Other  \n",
       "115501    city_1        male  28.0                                 Other  \n",
       "100718   city_10        male  13.0                                 Other  \n",
       "154871    city_1         NaN   NaN                                   NaN  \n",
       "154872    city_1        male  19.0                    Kirori Mal College  \n",
       "210312    city_1         NaN   NaN                                   NaN  \n",
       "210313    city_1        male  19.0                    Kirori Mal College  \n",
       "139291    city_1         NaN   NaN                                   NaN  \n",
       "108275    city_1  non_binary  13.0  Delhi Technological University (DTU)  \n",
       "108276    city_1  non_binary  13.0  Delhi Technological University (DTU)  \n",
       "108347    city_1        male  22.0                                   NaN  \n",
       "108348    city_1        male  22.0                                   NaN  \n",
       "108349    city_1        male  22.0                                   NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of interactions to be removed: 13712 (5.92%)\n",
      "(217827, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>createdAt</th>\n",
       "      <th>user_code</th>\n",
       "      <th>poll_code</th>\n",
       "      <th>event</th>\n",
       "      <th>country</th>\n",
       "      <th>city_code</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>college_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-12-19 16:30:24</td>\n",
       "      <td>user_50</td>\n",
       "      <td>poll_47</td>\n",
       "      <td>Polls Answered</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-12-19 16:30:25</td>\n",
       "      <td>user_21</td>\n",
       "      <td>poll_47</td>\n",
       "      <td>Polls Answered</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-12-19 16:30:26</td>\n",
       "      <td>user_10</td>\n",
       "      <td>poll_47</td>\n",
       "      <td>Polls Answered</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-12-19 16:30:27</td>\n",
       "      <td>user_6</td>\n",
       "      <td>poll_47</td>\n",
       "      <td>Polls Answered</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-12-19 16:30:27</td>\n",
       "      <td>user_70</td>\n",
       "      <td>poll_47</td>\n",
       "      <td>Polls Answered</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            createdAt user_code poll_code           event country city_code  \\\n",
       "0 2022-12-19 16:30:24   user_50   poll_47  Polls Answered     NaN       NaN   \n",
       "1 2022-12-19 16:30:25   user_21   poll_47  Polls Answered     NaN       NaN   \n",
       "2 2022-12-19 16:30:26   user_10   poll_47  Polls Answered     NaN       NaN   \n",
       "3 2022-12-19 16:30:27    user_6   poll_47  Polls Answered     NaN       NaN   \n",
       "4 2022-12-19 16:30:27   user_70   poll_47  Polls Answered     NaN       NaN   \n",
       "\n",
       "  gender  age college_code  \n",
       "0    NaN  NaN          NaN  \n",
       "1    NaN  NaN          NaN  \n",
       "2    NaN  NaN          NaN  \n",
       "3    NaN  NaN          NaN  \n",
       "4    NaN  NaN          NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ---\n",
    "# jupyter:\n",
    "#   jupytext:\n",
    "#     cell_metadata_filter: -all\n",
    "#     custom_cell_magics: kql\n",
    "#     text_representation:\n",
    "#       extension: .py\n",
    "#       format_name: percent\n",
    "#       format_version: '1.3'\n",
    "#       jupytext_version: 1.11.2\n",
    "#   kernelspec:\n",
    "#     display_name: hunch_assignment\n",
    "#     language: python\n",
    "#     name: python3\n",
    "# ---\n",
    "\n",
    "# %% [markdown]\n",
    "# # Setup\n",
    "\n",
    "# %%\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimpy import skim\n",
    "# %%\n",
    "from IPython.display import display\n",
    "\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "# %% [markdown]\n",
    "# # Read raw data\n",
    "\n",
    "# %%\n",
    "data_path = os.path.join(\"data\", \"raw\")\n",
    "file_name = \"events.pkl\"\n",
    "file_path = os.path.join(data_path, file_name)\n",
    "\n",
    "# %%\n",
    "events_raw: pd.DataFrame = None  # type: ignore\n",
    "if events_raw is None:\n",
    "    events_raw = pd.read_pickle(file_path)\n",
    "\n",
    "# %%\n",
    "display(events_raw.head())\n",
    "display(events_raw.info())\n",
    "\n",
    "# %%\n",
    "skim(events_raw.apply(lambda x: x.astype(\"category\") if x.dtype == \"object\" else x))\n",
    "\n",
    "# %% [markdown]\n",
    "# # Make a backup\n",
    "\n",
    "# %%\n",
    "events = events_raw.copy()\n",
    "\n",
    "# %% [markdown]\n",
    "# # Clean\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Handling potential duplicates\n",
    "\n",
    "# %%\n",
    "temp = (\n",
    "    events.groupby([\"user_code\", \"poll_code\", \"event\", \"createdAt\"])\n",
    "    .filter(lambda x: x.shape[0] > 1)\n",
    "    .sort_values(by=[\"event\", \"user_code\", \"poll_code\", \"createdAt\"])\n",
    ")\n",
    "\n",
    "# %%\n",
    "print(f\"No. of potential duplicates: {temp.shape[0]}\")\n",
    "for col in [\"user_code\", \"poll_code\", \"event\"]:\n",
    "    print(f\"\\n{col}: {temp[col].value_counts(dropna=False, normalize=True).iloc[:5]}\")\n",
    "display(temp.groupby([\"event\"]).head())\n",
    "\n",
    "# %% [markdown]\n",
    "# Different options for some reason! Does not make sense. Let's drop them.\n",
    "\n",
    "# %%\n",
    "primary_key = [\"user_code\", \"poll_code\", \"event\", \"createdAt\"]\n",
    "\n",
    "events.drop_duplicates(subset=primary_key, ignore_index=True, inplace=True)\n",
    "\n",
    "assert events.shape[0] == events.groupby(primary_key).ngroups\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Handle rows with same user, poll, and event\n",
    "\n",
    "# %%\n",
    "events.sort_values([\"createdAt\"], inplace=True)\n",
    "\n",
    "is_same_event = events.duplicated(subset=[\"user_code\", \"poll_code\", \"event\"], keep=\"last\")\n",
    "\n",
    "print(\n",
    "    f\"No. of interactions to be removed: {is_same_event.sum()} ({is_same_event.sum()/events.shape[0]*100:.2f}%)\"\n",
    ")\n",
    "\n",
    "# %%\n",
    "events = events[~is_same_event].copy().reset_index(drop=True)\n",
    "\n",
    "# %% [markdown]\n",
    "# # Write\n",
    "\n",
    "# %%\n",
    "print(events.shape)\n",
    "display(events.head())\n",
    "\n",
    "# %%\n",
    "data_path = os.path.join(\"data\", \"prepared\")\n",
    "file_name = \"events.pkl\"\n",
    "file_path = os.path.join(data_path, file_name)\n",
    "\n",
    "# %%\n",
    "pd.to_pickle(events, file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ecf0ad-bf08-4849-a053-539aedda460c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "42ce2882-4e21-4599-bb08-b2b82fa577e5",
   "metadata": {},
   "source": [
    "## Raw events to interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f99947e-6284-40fd-90dd-3e909d8f5978",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandarallel\n",
    "# !pip install plotly\n",
    "# !pip install fuzzywuzzy\n",
    "# !pip install pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c746ba8-6377-4695-a0bf-c964b4d17a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---\n",
    "# jupyter:\n",
    "#   jupytext:\n",
    "#     cell_metadata_filter: -all\n",
    "#     custom_cell_magics: kql\n",
    "#     text_representation:\n",
    "#       extension: .py\n",
    "#       format_name: percent\n",
    "#       format_version: '1.3'\n",
    "#       jupytext_version: 1.11.2\n",
    "#   kernelspec:\n",
    "#     display_name: hunch_assignment\n",
    "#     language: python\n",
    "#     name: python3\n",
    "# ---\n",
    "\n",
    "# %% [markdown]\n",
    "# # Setup\n",
    "\n",
    "# %%\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimpy import skim\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "from box import Box\n",
    "from fuzzywuzzy import fuzz, process\n",
    "from collections import defaultdict\n",
    "import pickle\n",
    "from itertools import product\n",
    "from pandarallel import pandarallel\n",
    "\n",
    "from mlops.utils import get_polls_data_from_interaction_data, get_users_data_from_interaction_data\n",
    "\n",
    "\n",
    "# %%\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "# %%\n",
    "pandarallel.initialize()\n",
    "\n",
    "# %% [markdown]\n",
    "# # Read data\n",
    "\n",
    "# %%\n",
    "data_path = os.path.join(\"data\", \"prepared\")\n",
    "file_name = \"events.pkl\"\n",
    "file_path = os.path.join(data_path, file_name)\n",
    "\n",
    "# %%\n",
    "events: pd.DataFrame = None  # type: ignore\n",
    "if events is None:\n",
    "    events = pd.read_pickle(\n",
    "        file_path,\n",
    "    )\n",
    "\n",
    "# %%\n",
    "display(events.head())\n",
    "\n",
    "# %%\n",
    "skim(events.apply(lambda x: x.astype(\"category\") if x.dtype == \"object\" else x))\n",
    "\n",
    "\n",
    "# %% [markdown]\n",
    "# # Assign score per event\n",
    "\n",
    "# %%\n",
    "event_score_dict = {\"Impression\": 0, \"Expand\": 1, \"Polls Answered\": 2, \"Shares\": 3}\n",
    "events[\"event_score\"] = events[\"event\"].map(event_score_dict)\n",
    "\n",
    "\n",
    "# %% [markdown]\n",
    "# # Get Users data\n",
    "\n",
    "# %%\n",
    "users = get_users_data_from_interaction_data(events.copy())\n",
    "\n",
    "# %%\n",
    "display(users.head())\n",
    "\n",
    "# %%\n",
    "temp = users[\"n_interactive_polls\"].value_counts(sort=False).sort_index()\n",
    "print(\n",
    "    f\"\"\"Users with no interactions, just impressions: {temp[0]} ({(temp[0] / users.shape[0] * 100):.2f}%)\"\"\"\n",
    ")\n",
    "\n",
    "temp = users[\"n_polls\"].value_counts(sort=False).sort_index()\n",
    "print(f\"\"\"Users with just 1 poll: {temp[1]} ({(temp[1] / users.shape[0] * 100):.2f}%)\"\"\")\n",
    "\n",
    "\n",
    "print(\n",
    "    f\"\"\"Users with no useful location data: {users[\"has_no_useful_location_data\"] .sum()} ({(users[\"has_no_useful_location_data\"] .sum() / users.shape[0] * 100):.2f}%)\"\"\"\n",
    ")\n",
    "\n",
    "\n",
    "print(\n",
    "    f\"\"\"Users with no useful identity data: {users[\"has_no_useful_identity_data\"].sum()} ({(users[\"has_no_useful_identity_data\"].sum() / users.shape[0] * 100):.2f}%)\"\"\"\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"\"\"Users with no useful user data: {users[\"has_no_useful_user_data\"].sum()} ({(users[\"has_no_useful_user_data\"].sum() / users.shape[0] * 100):.2f}%)\"\"\"\n",
    ")\n",
    "\n",
    "# %%\n",
    "skim(users.apply(lambda x: x.astype(\"category\") if x.dtype == \"object\" else x))\n",
    "\n",
    "# %%\n",
    "for col in [\"country\", \"city_code\", \"gender\", \"college_code\"]:\n",
    "    counts = users[col].value_counts(dropna=True, normalize=True).reset_index()\n",
    "    counts[\"proportion_cumulative\"] = counts[\"proportion\"].cumsum().div(counts[\"proportion\"].sum())\n",
    "    index = (\n",
    "        counts.loc[counts[\"proportion_cumulative\"] > 0.9, \"proportion_cumulative\"].idxmin()\n",
    "    ) + 1\n",
    "    index = max(index, 5)\n",
    "    print(f\"\\n{counts.iloc[0:index, 0:2]}\")\n",
    "\n",
    "# %%\n",
    "for col in [\n",
    "    \"age\",\n",
    "    \"n_polls\",\n",
    "    \"n_interactive_polls_proportion\",\n",
    "    \"event_score_by_user_per_interactive_poll\",\n",
    "]:\n",
    "    display(\n",
    "        users[col].describe(\n",
    "            percentiles=np.concatenate(\n",
    "                [\n",
    "                    np.arange(0.01, 0.06, 0.01),\n",
    "                    [0.1],\n",
    "                    np.arange(0.25, 0.8, 0.25),\n",
    "                    [0.9],\n",
    "                    np.arange(0.95, 0.99, 0.01),\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "\n",
    "# %% [markdown]\n",
    "# ### Binning Age\n",
    "\n",
    "# %%\n",
    "is_younger_than_teen = users[\"age\"] < 13\n",
    "is_older_than_40 = users[\"age\"] > 40\n",
    "\n",
    "is_invalid_age = is_younger_than_teen | is_older_than_40\n",
    "\n",
    "users[\"age\"] = users[\"age\"].where(~is_invalid_age)\n",
    "\n",
    "# %%\n",
    "users[\"age\"].describe(\n",
    "    percentiles=np.concatenate(\n",
    "        [\n",
    "            np.arange(0.01, 0.06, 0.01),\n",
    "            [0.1],\n",
    "            np.arange(0.25, 0.8, 0.25),\n",
    "            [0.9],\n",
    "            np.arange(0.95, 0.99, 0.01),\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "\n",
    "# %%\n",
    "bins = [0, 16, 18, 22, 25, 30, 40]\n",
    "labels = [f\"({bins[i]}-{bins[i+1]}]\" for i in range(len(bins) - 1)]\n",
    "print(labels)\n",
    "users[\"age_binned\"] = pd.cut(\n",
    "    users[\"age\"], bins=bins, labels=labels, right=True, include_lowest=False\n",
    ").astype(\"object\")\n",
    "\n",
    "# %%\n",
    "users[\"age_binned\"].value_counts(dropna=True, normalize=True)\n",
    "\n",
    "# %% [markdown]\n",
    "# ### Reduce no. of city and college codes\n",
    "\n",
    "# %% [markdown]\n",
    "# Note: College already has \"Other\"\n",
    "\n",
    "# %%\n",
    "min_code_proportion = 0.01\n",
    "for col in [\"city_code\", \"college_code\"]:\n",
    "    code_propoptions = users[col].value_counts(dropna=True, normalize=True)\n",
    "    codes_to_replace = code_propoptions[code_propoptions < min_code_proportion].index\n",
    "    users[col + \"_trimmed\"] = users[col].replace(codes_to_replace, \"Other\").copy()\n",
    "    print(users[col + \"_trimmed\"].value_counts(dropna=True, normalize=True))\n",
    "\n",
    "# %% [markdown]\n",
    "# ### Fill missing\n",
    "\n",
    "# %%\n",
    "users[\"country_filled\"] = users[\"country\"].copy()\n",
    "users[\"gender_filled\"] = users[\"gender\"].copy()\n",
    "\n",
    "# %%\n",
    "for col in [\n",
    "    \"country_filled\",\n",
    "    \"gender_filled\",\n",
    "    \"age_binned\",\n",
    "    \"city_code_trimmed\",\n",
    "    \"college_code_trimmed\",\n",
    "]:\n",
    "    users[col].fillna(\"Missing\", inplace=True)\n",
    "\n",
    "\n",
    "# %% [markdown]\n",
    "# # Get Polls data\n",
    "\n",
    "# %%\n",
    "polls = get_polls_data_from_interaction_data(events.copy())\n",
    "\n",
    "# %%\n",
    "display(polls.head())\n",
    "\n",
    "# %%\n",
    "skim(polls.apply(lambda x: x.astype(\"category\") if x.dtype == \"object\" else x))\n",
    "\n",
    "# %%\n",
    "for col in [\n",
    "    \"n_users\",\n",
    "    \"n_interactive_users_proportion\",\n",
    "    \"event_score_by_poll_per_interactive_user\",\n",
    "]:\n",
    "    display(\n",
    "        polls[col].describe(\n",
    "            percentiles=np.concatenate(\n",
    "                [\n",
    "                    np.arange(0.01, 0.06, 0.01),\n",
    "                    [0.1],\n",
    "                    np.arange(0.25, 0.8, 0.25),\n",
    "                    [0.9],\n",
    "                    np.arange(0.95, 0.99, 0.01),\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Collapse event types\n",
    "\n",
    "# %%\n",
    "events.sort_values([\"event_score\"], inplace=True)\n",
    "\n",
    "is_same_user_poll = events.duplicated(subset=[\"user_code\", \"poll_code\"], keep=\"last\")\n",
    "\n",
    "print(\n",
    "    f\"No. of different events for same user-poll to be collapsed: {is_same_user_poll.sum()} ({is_same_user_poll.sum()/events.shape[0]*100:.2f}%)\"\n",
    ")\n",
    "\n",
    "# %%\n",
    "interactions = events[~is_same_user_poll].copy().reset_index(drop=True)\n",
    "assert interactions.shape[0] == interactions.groupby([\"poll_code\", \"user_code\"]).ngroups\n",
    "primary_key = [\"user_code\", \"poll_code\"]\n",
    "\n",
    "# %%\n",
    "skim(interactions.apply(lambda x: x.astype(\"category\") if x.dtype == \"object\" else x))\n",
    "\n",
    "# %% [markdown]\n",
    "# # Write\n",
    "\n",
    "# %%\n",
    "pd.to_pickle(interactions, os.path.join(data_path, \"interactions.pkl\"))\n",
    "pd.to_pickle(users, os.path.join(data_path, \"users.pkl\"))\n",
    "pd.to_pickle(polls, os.path.join(data_path, \"polls.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7614706-778f-487f-ae0d-c6d939f71bdc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "76671cc9-3ad3-46af-9511-1a8d21d9922c",
   "metadata": {},
   "source": [
    "## Prepare for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47bf37a6-77f6-4948-8945-abcead9b8110",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---\n",
    "# jupyter:\n",
    "#   jupytext:\n",
    "#     cell_metadata_filter: -all\n",
    "#     custom_cell_magics: kql\n",
    "#     text_representation:\n",
    "#       extension: .py\n",
    "#       format_name: percent\n",
    "#       format_version: '1.3'\n",
    "#       jupytext_version: 1.11.2\n",
    "#   kernelspec:\n",
    "#     display_name: hunch_assignment\n",
    "#     language: python\n",
    "#     name: python3\n",
    "# ---\n",
    "\n",
    "# %% [markdown]\n",
    "# # Setup\n",
    "\n",
    "# %%\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "from skimpy import skim\n",
    "\n",
    "\n",
    "# %%\n",
    "from IPython.display import display\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "# %% [markdown]\n",
    "# # Read data\n",
    "\n",
    "# %%\n",
    "data_path = os.path.join(\"data\", \"prepared\")\n",
    "\n",
    "# %%\n",
    "file_name = \"interactions.pkl\"\n",
    "file_path = os.path.join(data_path, file_name)\n",
    "interactions: pd.DataFrame = None # type: ignore\n",
    "if interactions is None:\n",
    "    interactions = pd.read_pickle(\n",
    "        file_path,\n",
    "    )\n",
    "assert interactions.shape[0] == interactions.groupby(['user_code', 'poll_code']).ngroups\n",
    "display(interactions.head())    \n",
    "\n",
    "# %%\n",
    "file_name = \"users.pkl\"\n",
    "file_path = os.path.join(data_path, file_name)\n",
    "users: pd.DataFrame = None # type: ignore\n",
    "if users is None:\n",
    "    users = pd.read_pickle(\n",
    "        file_path,\n",
    "    )\n",
    "assert users.shape[0] == users[\"user_code\"].nunique()    \n",
    "display(users.head())   \n",
    "\n",
    "# %%\n",
    "file_name = \"polls.pkl\"\n",
    "file_path = os.path.join(data_path, file_name)\n",
    "polls: pd.DataFrame = None # type: ignore\n",
    "if polls is None:\n",
    "    polls = pd.read_pickle(\n",
    "        file_path,\n",
    "    )\n",
    "assert polls.shape[0] == polls[\"poll_code\"].nunique()    \n",
    "display(polls.head())   \n",
    "\n",
    "\n",
    "# %% [markdown]\n",
    "# # Delete irrelevant users and polls\n",
    "\n",
    "# %% [markdown]\n",
    "# Users with 0% interactive polls are not relevant for our purpose because we can neither learn anything from them, nor use them in the test set. Same goes for polls with 0% interactive users. So, let's delete them.\n",
    "\n",
    "# %%\n",
    "users_with_zero_interactive_polls = users.loc[\n",
    "    users[\"has_no_interactive_polls\"], \"user_code\"\n",
    "].values\n",
    "print(\n",
    "    f\"Users with zero interactive polls: {len(users_with_zero_interactive_polls)} ({len(users_with_zero_interactive_polls)/users.shape[0]*100:.2f}%)\"\n",
    ")\n",
    "\n",
    "polls_with_zero_interactive_users = polls.loc[\n",
    "    polls[\"has_no_interactive_users\"], \"poll_code\"\n",
    "].values\n",
    "print(\n",
    "    f\"Polls with zero interactive users: {len(polls_with_zero_interactive_users)} ({len(polls_with_zero_interactive_users)/polls.shape[0]*100:.2f}%)\"\n",
    ")\n",
    "\n",
    "# %%\n",
    "users = users[~users[\"has_no_interactive_polls\"]].copy().reset_index(drop=True)\n",
    "users.drop(columns=[\"has_no_interactive_polls\"], inplace=True)\n",
    "\n",
    "assert users.shape[0] == users[\"user_code\"].nunique()\n",
    "\n",
    "polls = polls[~polls[\"has_no_interactive_users\"]].copy().reset_index(drop=True)\n",
    "polls.drop(columns=[\"has_no_interactive_users\"], inplace=True)\n",
    "\n",
    "assert polls.shape[0] == polls[\"poll_code\"].nunique()\n",
    "\n",
    "n_polls = polls.shape[0]\n",
    "n_users = users.shape[0]\n",
    "\n",
    "print(f\"n_users: {n_users}\")\n",
    "print(f\"n_polls: {n_polls}\")\n",
    "\n",
    "# %%\n",
    "is_non_interactive_user = interactions[\"user_code\"].isin(users_with_zero_interactive_polls)\n",
    "is_non_interactive_poll = interactions[\"poll_code\"].isin(polls_with_zero_interactive_users)\n",
    "\n",
    "is_non_interactive = is_non_interactive_user | is_non_interactive_poll\n",
    "\n",
    "print(\n",
    "    f\"User-poll interactions to be removed: {is_non_interactive.sum()} ({is_non_interactive.sum()/interactions.shape[0]*100:.2f}%)\"\n",
    ")\n",
    "\n",
    "# %%\n",
    "rows_before = interactions.shape[0]\n",
    "interactions = interactions[~is_non_interactive].copy().reset_index(drop=True)\n",
    "rows_after = interactions.shape[0]\n",
    "assert rows_before - rows_after == is_non_interactive.sum()\n",
    "\n",
    "# %%\n",
    "assert set(set(interactions[\"user_code\"].unique())).issubset(set(users[\"user_code\"]))\n",
    "assert set(set(users[\"user_code\"])).issubset(set(interactions[\"user_code\"].unique()))\n",
    "\n",
    "assert set(set(interactions[\"poll_code\"].unique())).issubset(set(polls[\"poll_code\"]))\n",
    "assert set(set(polls[\"poll_code\"])).issubset(set(interactions[\"poll_code\"].unique()))\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Concise Summary:\n",
    "\n",
    "# %%\n",
    "print(f\"Total number of unique user-poll interactions: {interactions.shape[0]}\")\n",
    "print(\n",
    "    f\"\"\"\\nDistribution by event type:\\n{interactions[\"event\"].value_counts(dropna=False, normalize=True)}\"\"\"\n",
    ")\n",
    "n_polls = interactions[\"poll_code\"].nunique()\n",
    "n_users = interactions[\"user_code\"].nunique()\n",
    "print(f\"\\nn_users: {n_users}\")\n",
    "print(f\"n_polls: {n_polls}\")\n",
    "skim(\n",
    "    interactions.apply(lambda x: x.astype(\"category\") if x.dtype == \"object\" else x)\n",
    ")\n",
    "\n",
    "# %% [markdown]\n",
    "# # Write\n",
    "\n",
    "# %%\n",
    "pd.to_pickle(interactions, os.path.join(data_path, \"interactions_relevant.pkl\"))\n",
    "pd.to_pickle(users, os.path.join(data_path, \"users_relevant.pkl\"))\n",
    "pd.to_pickle(polls, os.path.join(data_path, \"polls_relevant.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c512f7-307a-462d-a35d-cf1a7751fa98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519eb7a8-4656-48ce-b00a-1887723fadf4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0c1568-fe88-42c1-8cdb-6f2d2455a170",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "78f3a0e7-1204-454c-b608-b16000e32279",
   "metadata": {},
   "source": [
    "## Model Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad613775-2666-4004-bfe1-128641109def",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---\n",
    "# jupyter:\n",
    "#   jupytext:\n",
    "#     cell_metadata_filter: -all\n",
    "#     custom_cell_magics: kql\n",
    "#     text_representation:\n",
    "#       extension: .py\n",
    "#       format_name: percent\n",
    "#       format_version: '1.3'\n",
    "#       jupytext_version: 1.11.2\n",
    "#   kernelspec:\n",
    "#     display_name: hunch_assignment\n",
    "#     language: python\n",
    "#     name: python3\n",
    "# ---\n",
    "\n",
    "# %% [markdown]\n",
    "# # Setup\n",
    "\n",
    "# %%\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimpy import skim\n",
    "from collections import defaultdict\n",
    "from pandarallel import pandarallel\n",
    "\n",
    "from mlops.evaluate import convert_df_to_dict, eval_add_show\n",
    "from mlops.utils import get_polls_data_from_interaction_data, get_users_data_from_interaction_data\n",
    "\n",
    "\n",
    "# %%\n",
    "from IPython.display import display\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "# %%\n",
    "pandarallel.initialize()\n",
    "\n",
    "# %% [markdown]\n",
    "# # Read data\n",
    "\n",
    "# %%\n",
    "data_path = os.path.join(\"data\", \"prepared\")\n",
    "\n",
    "# %%\n",
    "file_name = \"interactions_relevant.pkl\"\n",
    "file_path = os.path.join(data_path, file_name)\n",
    "interactions: pd.DataFrame = None # type: ignore\n",
    "if interactions is None:\n",
    "    interactions = pd.read_pickle(\n",
    "        file_path,\n",
    "    )\n",
    "assert interactions.shape[0] == interactions.groupby(['user_code', 'poll_code']).ngroups\n",
    "display(interactions.head())    \n",
    "\n",
    "# %%\n",
    "file_name = \"users_relevant.pkl\"\n",
    "file_path = os.path.join(data_path, file_name)\n",
    "users: pd.DataFrame = None # type: ignore\n",
    "if users is None:\n",
    "    users = pd.read_pickle(\n",
    "        file_path,\n",
    "    )\n",
    "assert users.shape[0] == users[\"user_code\"].nunique()    \n",
    "display(users.head())   \n",
    "\n",
    "# %%\n",
    "file_name = \"polls_relevant.pkl\"\n",
    "file_path = os.path.join(data_path, file_name)\n",
    "polls: pd.DataFrame = None # type: ignore\n",
    "if polls is None:\n",
    "    polls = pd.read_pickle(\n",
    "        file_path,\n",
    "    )\n",
    "assert polls.shape[0] == polls[\"poll_code\"].nunique()    \n",
    "display(polls.head())   \n",
    "\n",
    "\n",
    "# %% [markdown]\n",
    "# # Train test split\n",
    "\n",
    "# %%\n",
    "print(\"User data split:\")\n",
    "display(\n",
    "    pd.crosstab(\n",
    "        users[\"has_just_one_poll\"],\n",
    "        users[\"has_no_useful_identity_data\"],\n",
    "        rownames=[\"is new user\"],\n",
    "        colnames=[\"no identity data\"],\n",
    "        margins=True,\n",
    "        normalize=True,\n",
    "    ).apply(lambda x: (x * 100).round(2))\n",
    ")\n",
    "\n",
    "# %%\n",
    "users_has_columns = users.columns[users.columns.str.contains(\"has_\")].tolist()\n",
    "\n",
    "if not all([x in interactions.columns for x in users_has_columns]):\n",
    "    rows_before = interactions.shape[0]    \n",
    "    interactions = interactions.merge(\n",
    "        users[\n",
    "            [\"user_code\", *users_has_columns]\n",
    "        ],\n",
    "        on=\"user_code\",\n",
    "        how=\"left\",\n",
    "    )\n",
    "    rows_after = interactions.shape[0]\n",
    "    assert rows_before == rows_after\n",
    "\n",
    "group_name_dict = {\n",
    "    (True, True): (\"new\", \"no_identity_data\"),\n",
    "    (True, False): (\"new\", \"with_identity_data\"),\n",
    "    (False, True): (\"existing\", \"no_identity_data\"),\n",
    "    (False, False): (\"existing\", \"with_identity_data\"),\n",
    "}\n",
    "\n",
    "grouped_data = (\n",
    "    interactions\n",
    "    .groupby([\"has_just_one_poll\", \"has_no_useful_identity_data\"])\n",
    ")\n",
    "\n",
    "grouped_data_dict = {\n",
    "    group_name_dict[group_name]: group_data for group_name, group_data in grouped_data\n",
    "}\n",
    "\n",
    "# %%\n",
    "train_data_dict = {}\n",
    "test_data_dict = {}\n",
    "\n",
    "for key, value in grouped_data_dict.items():\n",
    "    # value = value.sort_values([\"createdAt\"]).copy()\n",
    "    if key[0] == \"new\":\n",
    "        test_indexes = (\n",
    "            value[value[\"event\"] != \"Impression\"]   # because we want only interactive polls in test\n",
    "            .groupby([\"poll_code\"])    \n",
    "            .filter(lambda x: len(x) > 1)   # if the poll has just this one user, then that poll should be present in train for it to be available for recommendation\n",
    "            .groupby([\"poll_code\"])\n",
    "            .apply(lambda x: x.sample(frac=0.1, random_state=123))\n",
    "            .reset_index(level=[0], drop=True)\n",
    "            .index\n",
    "        )\n",
    "    else:\n",
    "        test_indexes = (\n",
    "            value[value[\"event\"] != \"Impression\"]   # because we want only interactive polls in test\n",
    "            .groupby([\"poll_code\"])\n",
    "            .filter(lambda x: len(x) > 2)  # to ensure that test polls are in train too\n",
    "            .sample(frac=0.2, random_state=123)\n",
    "            .index\n",
    "        )\n",
    "    test_data_dict[key] = value.loc[test_indexes]\n",
    "    train_data_dict[key] = value.drop(test_indexes)\n",
    "\n",
    "# %%\n",
    "train_data = pd.concat(train_data_dict.values(), keys=train_data_dict.keys()).reset_index(drop=True)\n",
    "train_users = get_users_data_from_interaction_data(train_data.copy())\n",
    "train_polls = get_polls_data_from_interaction_data(train_data.copy())\n",
    "\n",
    "assert set(train_data[\"user_code\"].unique()).issubset(set(train_users[\"user_code\"]))\n",
    "assert set(train_users[\"user_code\"]).issubset(train_data[\"user_code\"].unique())\n",
    "assert set(train_data[\"poll_code\"].unique()).issubset(set(train_polls[\"poll_code\"]))\n",
    "assert set(train_polls[\"poll_code\"]).issubset(train_data[\"poll_code\"].unique())\n",
    "\n",
    "print(\"train:\")\n",
    "print(f\"{train_data.shape}\")\n",
    "print(f\"\"\"Users in train data: {len(train_data[\"user_code\"].unique())}\"\"\")\n",
    "print(f\"\"\"Polls in train data: {len(train_data[\"poll_code\"].unique())}\"\"\")\n",
    "print(\"User-poll interaction split:\")\n",
    "display(\n",
    "    pd.crosstab(\n",
    "        train_data[\"has_just_one_poll\"],\n",
    "        train_data[\"has_no_useful_identity_data\"],\n",
    "        rownames=[\"is new user\"],\n",
    "        colnames=[\"no identity data\"],\n",
    "        margins=True,\n",
    "        normalize=True,\n",
    "    ).apply(lambda x: (x * 100).round(2))\n",
    ")\n",
    "\n",
    "test_data = pd.concat(test_data_dict.values(), keys=test_data_dict.keys()).reset_index(drop=True)\n",
    "test_users = get_users_data_from_interaction_data(test_data.copy())\n",
    "test_polls = get_polls_data_from_interaction_data(test_data.copy())\n",
    "\n",
    "assert set(test_data[\"user_code\"].unique()).issubset(set(test_users[\"user_code\"]))\n",
    "assert set(test_users[\"user_code\"]).issubset(test_data[\"user_code\"].unique())\n",
    "assert set(test_data[\"poll_code\"].unique()).issubset(set(test_polls[\"poll_code\"]))\n",
    "assert set(test_polls[\"poll_code\"]).issubset(test_data[\"poll_code\"].unique())\n",
    "\n",
    "print(\"\\ntest:\")\n",
    "print(f\"{test_data.shape}\")\n",
    "print(f\"\"\"Users in test data: {len(test_data[\"user_code\"].unique())}\"\"\")\n",
    "print(f\"\"\"Polls in test data: {len(test_data[\"poll_code\"].unique())}\"\"\")\n",
    "print(\"User-poll interaction split:\")\n",
    "display(\n",
    "    pd.crosstab(\n",
    "        test_data[\"has_just_one_poll\"],\n",
    "        test_data[\"has_no_useful_identity_data\"],\n",
    "        rownames=[\"is new user\"],\n",
    "        colnames=[\"no identity data\"],\n",
    "        margins=True,\n",
    "        normalize=True,\n",
    "    ).apply(lambda x: (x * 100).round(2))\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"\"\"\\nTest users in train: {np.isin(test_data[\"user_code\"].unique(), train_data[\"user_code\"].unique()).sum() / len(test_data[\"user_code\"].unique())* 100:.2f}%\"\"\"\n",
    ")\n",
    "print(\n",
    "    f\"\"\"Test polls in train: {np.isin(test_data[\"poll_code\"].unique(), train_data[\"poll_code\"].unique()).sum() / len(test_data[\"poll_code\"].unique())* 100:.2f}%\"\"\"\n",
    ")\n",
    "\n",
    "\n",
    "assert train_data.shape[0] + test_data.shape[0] == interactions.shape[0]\n",
    "\n",
    "# %%\n",
    "print(\"Distribution of polls per user in train\")\n",
    "display(train_users[\"n_interactive_polls\"].describe(np.arange(0.1, 1, 0.1)).to_frame().T)\n",
    "\n",
    "print(\"Distribution of polls per user in test\")\n",
    "display(test_users[\"n_interactive_polls\"].describe(np.arange(0.1, 1, 0.1)).to_frame().T)\n",
    "\n",
    "# %%\n",
    "assert interactions.shape[0] == interactions.groupby([\"poll_code\", \"user_code\"]).ngroups\n",
    "assert users.shape[0] == users[\"user_code\"].nunique()\n",
    "assert polls.shape[0] == polls[\"poll_code\"].nunique()\n",
    "\n",
    "assert set(interactions[\"user_code\"].unique()).issubset(set(users[\"user_code\"]))\n",
    "assert set(users[\"user_code\"]).issubset(interactions[\"user_code\"].unique())\n",
    "all_users = users[\"user_code\"]\n",
    "\n",
    "assert set(interactions[\"poll_code\"].unique()).issubset(set(polls[\"poll_code\"]))\n",
    "assert set(polls[\"poll_code\"]).issubset(interactions[\"poll_code\"].unique())\n",
    "all_polls = polls[\"poll_code\"]\n",
    "\n",
    "# %%\n",
    "assert train_data.shape[0] == train_data.groupby([\"poll_code\", \"user_code\"]).ngroups\n",
    "assert train_users.shape[0] == train_users[\"user_code\"].nunique()\n",
    "assert train_polls.shape[0] == train_polls[\"poll_code\"].nunique()\n",
    "\n",
    "assert set(train_data[\"user_code\"].unique()).issubset(set(train_users[\"user_code\"]))\n",
    "assert set(train_users[\"user_code\"]).issubset(train_data[\"user_code\"].unique())\n",
    "train_users_users = train_users[\"user_code\"]\n",
    "\n",
    "\n",
    "assert set(train_data[\"poll_code\"].unique()).issubset(set(train_polls[\"poll_code\"]))\n",
    "assert set(train_polls[\"poll_code\"]).issubset(train_data[\"poll_code\"].unique())\n",
    "train_polls_polls = train_polls[\"poll_code\"]\n",
    "\n",
    "# %%\n",
    "assert test_data.shape[0] == test_data.groupby([\"poll_code\", \"user_code\"]).ngroups\n",
    "assert test_users.shape[0] == test_users[\"user_code\"].nunique()\n",
    "assert test_polls.shape[0] == test_polls[\"poll_code\"].nunique()\n",
    "\n",
    "assert set(test_data[\"user_code\"].unique()).issubset(set(test_users[\"user_code\"]))\n",
    "assert set(test_users[\"user_code\"]).issubset(test_data[\"user_code\"].unique())\n",
    "test_users_users = test_users[\"user_code\"]\n",
    "\n",
    "\n",
    "assert set(test_data[\"poll_code\"].unique()).issubset(set(test_polls[\"poll_code\"]))\n",
    "assert set(test_polls[\"poll_code\"]).issubset(test_data[\"poll_code\"].unique())\n",
    "test_polls_polls = test_polls[\"poll_code\"]\n",
    "\n",
    "# %% [markdown]\n",
    "# # Data prep. for model\n",
    "\n",
    "# %%\n",
    "print(f\"Total train users: {len(train_users)}\")\n",
    "print(f\"Total train polls: {len(train_polls)}\")\n",
    "\n",
    "# get just those train polls that the user interacted with\n",
    "train_data_i = train_data[train_data[\"event_score\"] != 0].copy()\n",
    "train_users_with_interactions = train_data_i[\"user_code\"].unique()\n",
    "train_polls_with_interactions = train_data_i[\"poll_code\"].unique()\n",
    "\n",
    "print(f\"train users with interactions: {len(train_users_with_interactions)}\")\n",
    "print(f\"train polls with interactions: {len(train_polls_with_interactions)}\")\n",
    "\n",
    "# %%\n",
    "print(f\"Total test users: {len(test_users)}\")\n",
    "print(f\"Total test polls: {len(test_polls)}\")\n",
    "\n",
    "# convert it to dict format\n",
    "test_data_dict = convert_df_to_dict(\n",
    "    test_data[[\"user_code\", \"poll_code\", \"event_score\"]].copy(), with_pred_rating=True\n",
    ")\n",
    "\n",
    "# %%\n",
    "train_poll_codes_by_user = train_data.groupby(\"user_code\")[\"poll_code\"].agg(list).reset_index()\n",
    "train_poll_codes_by_user.rename(columns={\"poll_code\": \"train_poll_codes_list\"}, inplace=True)\n",
    "\n",
    "rows_before = test_data.shape[0]\n",
    "\n",
    "test_data = test_data.merge(train_poll_codes_by_user, on=\"user_code\", how=\"left\")\n",
    "test_data[\"train_poll_codes_list\"] = test_data[\"train_poll_codes_list\"].apply(\n",
    "    lambda d: d if isinstance(d, list) else []\n",
    ")\n",
    "rows_after = test_data.shape[0]\n",
    "\n",
    "assert rows_before == rows_after\n",
    "\n",
    "# %%\n",
    "test_users_in_train = test_users[np.isin(test_users, train_users)].copy()\n",
    "\n",
    "test_data_in_train = (\n",
    "    test_data[test_data[\"user_code\"].isin(test_users_in_train)].copy().reset_index(drop=True)\n",
    ")\n",
    "\n",
    "test_data_in_train_dict = (\n",
    "    test_data_in_train.groupby(\"user_code\")[[\"poll_code\", \"event_score\"]]\n",
    "    .apply(lambda g: list(map(tuple, g.values)))\n",
    "    .to_dict()\n",
    ")\n",
    "\n",
    "for user_code, recommendation in test_data_in_train_dict.items():\n",
    "    recommendation = dict(sorted(recommendation.items(), key=lambda x: x[1], reverse=True))\n",
    "    test_data_in_train_dict[user_code] = recommendation\n",
    "\n",
    "# %% [markdown]\n",
    "# # Modeling\n",
    "\n",
    "# %%\n",
    "model_results_comparison = pd.DataFrame()\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Basline-0: same top popular polls to every user\n",
    "\n",
    "# %%\n",
    "test_polls_set = set(test_polls)\n",
    "\n",
    "for popularity_metric in [\n",
    "    \"n_interactive_users\",\n",
    "    # \"event_score_sum_by_poll\",\n",
    "    # \"event_score_by_poll_per_interactive_user\",\n",
    "]:\n",
    "    recommended_polls = (\n",
    "        train_polls.sort_values(popularity_metric, ascending=False)[\"poll_code\"].reset_index(\n",
    "            drop=True\n",
    "        )\n",
    "        .copy()\n",
    "        .to_list()\n",
    "    )\n",
    "\n",
    "    df_recommended = test_users[[\"user_code\"]].copy()\n",
    "\n",
    "    rows_before = df_recommended.shape[0]\n",
    "    df_recommended = df_recommended.merge(\n",
    "        test_data[[\"user_code\", \"train_poll_codes_list\"]].drop_duplicates([\"user_code\"]),\n",
    "        on=\"user_code\",\n",
    "        how=\"left\",\n",
    "    )\n",
    "    rows_after = df_recommended.shape[0]\n",
    "    assert rows_before == rows_after\n",
    "\n",
    "    for n in [10, 25, 50]:\n",
    "        model_name = f\"Baseline: Top {n} polls by \" + popularity_metric\n",
    "        df_recommended[\"recommended_polls\"] = [recommended_polls] * df_recommended.shape[0]\n",
    "        df_recommended[\"recommended_polls_filtered\"] = df_recommended.parallel_apply(\n",
    "            lambda x: x[\"recommended_polls\"][0:n],\n",
    "            axis=1,\n",
    "        ) # type: ignore\n",
    "\n",
    "        # df_recommended[\"recommended_polls_filtered\"] = df_recommended.parallel_apply(\n",
    "        #     lambda x: [\n",
    "        #         poll for poll in x[\"recommended_polls\"] if poll not in x[\"train_poll_codes_list\"]\n",
    "        #     ][0:n],\n",
    "        #     axis=1,\n",
    "        # ) # type: ignore\n",
    "\n",
    "        recommendation_dict = df_recommended.set_index(\"user_code\")[\n",
    "            \"recommended_polls_filtered\"\n",
    "        ].to_dict()\n",
    "\n",
    "        (\n",
    "            ndcg_by_user,\n",
    "            precision_by_user,\n",
    "            recall_by_user,\n",
    "            results,\n",
    "            model_results_comparison,\n",
    "        ) = eval_add_show(\n",
    "            model_name,\n",
    "            recommendation_dict,\n",
    "            test_data_dict,\n",
    "            all_polls,\n",
    "            train_data[[\"user_code\", \"poll_code\", \"event_score\"]].copy(),\n",
    "            with_pred_rating=False,\n",
    "            model_results_comparison=model_results_comparison.copy(),\n",
    "            add=True,\n",
    "            show=False,\n",
    "        )\n",
    "with pd.option_context(\"display.float_format\", \"{:,.2%}\".format):\n",
    "    display(model_results_comparison)\n",
    "\n",
    "# %% [markdown]\n",
    "# ## SVD from `surprise` package\n",
    "\n",
    "# %%\n",
    "from surprise import Dataset, Reader, SVD\n",
    "\n",
    "# %%\n",
    "rating_min = train_data[\"event_score\"].min()\n",
    "rating_max = train_data[\"event_score\"].max()\n",
    "print(f\"Min rating: {rating_min}, Max rating: {rating_max}\")\n",
    "req_cols = [\"user_code\", \"poll_code\", \"event_score\"]\n",
    "\n",
    "reader = Reader(rating_scale=(rating_min, rating_max))\n",
    "train_data_surprise = Dataset.load_from_df(train_data[req_cols], reader).build_full_trainset()\n",
    "\n",
    "# %%\n",
    "algo = SVD(n_factors=10, n_epochs=40, lr_all=0.005, reg_all=0.1)\n",
    "algo.fit(train_data_surprise)\n",
    "\n",
    "\n",
    "# %%\n",
    "def get_test_predictions(algo, test_data, all_polls, is_filter_train_polls_out=False, n=50):\n",
    "    test_predictions_by_user = defaultdict(list)\n",
    "    for user_code in test_data[\"user_code\"].unique():\n",
    "        train_poll_codes_list = test_data.loc[\n",
    "            test_data[\"user_code\"] == user_code, \"train_poll_codes_list\"\n",
    "        ].values.tolist()[0]\n",
    "        if is_filter_train_polls_out:\n",
    "            candidate_polls = [poll for poll in all_polls if poll not in train_poll_codes_list]\n",
    "        else:\n",
    "            candidate_polls = all_polls\n",
    "        for poll_code in candidate_polls:\n",
    "            predicted_rating = algo.predict(user_code, poll_code).est\n",
    "            test_predictions_by_user[user_code].append((poll_code, predicted_rating))\n",
    "\n",
    "    for user_code, recommendation in test_predictions_by_user.items():\n",
    "        recommendation.sort(key=lambda x: x[1], reverse=True)\n",
    "        test_predictions_by_user[user_code] = recommendation[:n]\n",
    "\n",
    "    return test_predictions_by_user\n",
    "\n",
    "\n",
    "# %%\n",
    "for is_filter_train_polls_out in [False, True]:\n",
    "    for n in [10, 25, 50]:\n",
    "        test_predictions_by_user_topn = get_test_predictions(\n",
    "            algo, test_data, all_polls, is_filter_train_polls_out=is_filter_train_polls_out, n=n\n",
    "        )\n",
    "        model_name = f\"SVD: {n} - has_train_polls {is_filter_train_polls_out}\"\n",
    "        ndcg_by_user, precision_by_user, recall_by_user, results, model_results_comparison = eval_add_show(\n",
    "            model_name,\n",
    "            test_predictions_by_user_topn,\n",
    "            test_data_dict,\n",
    "            all_polls,\n",
    "            train_data[[\"user_code\", \"poll_code\", \"event_score\"]].copy(),\n",
    "            with_pred_rating=True,\n",
    "            model_results_comparison=model_results_comparison.copy(),\n",
    "            add=True,\n",
    "            show=False,\n",
    "        )\n",
    "\n",
    "# %%\n",
    "with pd.option_context(\"display.float_format\", \"{:,.2%}\".format):\n",
    "    display(model_results_comparison)\n",
    "\n",
    "# %%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hunch_assign",
   "language": "python",
   "name": "hunch_assign"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
